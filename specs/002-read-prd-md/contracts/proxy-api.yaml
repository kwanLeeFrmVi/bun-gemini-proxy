openapi: 3.0.3
info:
  title: Gemini Proxy API
  description: OpenAI-compatible proxy for Gemini API with automatic key rotation
  version: 1.0.0
  contact:
    name: Backend Engineering Team

servers:
  - url: http://localhost:4806
    description: Local development server

paths:
  /v1/chat/completions:
    post:
      summary: Create chat completion
      description: Forward chat completion requests to Gemini API with automatic key rotation
      operationId: createChatCompletion
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
      responses:
        '200':
          description: Successful chat completion
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionResponse'
        '400':
          description: Bad request - invalid payload
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '413':
          description: Payload too large
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '429':
          description: Rate limit exceeded on all keys
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '503':
          description: Service unavailable - all keys unhealthy
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'

  /v1/models:
    get:
      summary: List available models
      description: Return list of available Gemini models
      operationId: listModels
      responses:
        '200':
          description: List of available models
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelListResponse'

components:
  schemas:
    ChatCompletionRequest:
      type: object
      required:
        - model
        - messages
      properties:
        model:
          type: string
          description: Model identifier
          example: "gemini-pro"
        messages:
          type: array
          items:
            $ref: '#/components/schemas/ChatMessage'
        max_tokens:
          type: integer
          minimum: 1
          maximum: 4096
          description: Maximum tokens to generate
        temperature:
          type: number
          minimum: 0
          maximum: 2
          description: Sampling temperature
        stream:
          type: boolean
          description: Whether to stream responses
          default: false

    ChatMessage:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum: [system, user, assistant]
        content:
          type: string
          description: Message content

    ChatCompletionResponse:
      type: object
      required:
        - id
        - object
        - created
        - model
        - choices
      properties:
        id:
          type: string
          description: Unique completion identifier
        object:
          type: string
          enum: [chat.completion]
        created:
          type: integer
          description: Unix timestamp
        model:
          type: string
          description: Model used for completion
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatChoice'
        usage:
          $ref: '#/components/schemas/UsageStats'

    ChatChoice:
      type: object
      required:
        - index
        - message
        - finish_reason
      properties:
        index:
          type: integer
          description: Choice index
        message:
          $ref: '#/components/schemas/ChatMessage'
        finish_reason:
          type: string
          enum: [stop, length, content_filter]

    UsageStats:
      type: object
      properties:
        prompt_tokens:
          type: integer
        completion_tokens:
          type: integer
        total_tokens:
          type: integer

    ModelListResponse:
      type: object
      required:
        - object
        - data
      properties:
        object:
          type: string
          enum: [list]
        data:
          type: array
          items:
            $ref: '#/components/schemas/Model'

    Model:
      type: object
      required:
        - id
        - object
        - created
        - owned_by
      properties:
        id:
          type: string
          description: Model identifier
        object:
          type: string
          enum: [model]
        created:
          type: integer
          description: Unix timestamp
        owned_by:
          type: string
          description: Organization that owns the model

    ErrorResponse:
      type: object
      required:
        - error
      properties:
        error:
          type: object
          required:
            - message
            - type
          properties:
            message:
              type: string
              description: Human-readable error message
            type:
              type: string
              description: Error type identifier
            code:
              type: string
              description: Error code
            param:
              type: string
              description: Parameter that caused the error